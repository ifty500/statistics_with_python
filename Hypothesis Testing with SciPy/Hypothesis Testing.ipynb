{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Say you work for a major social media website. Your boss always says “data drives all our decisions” and it seems to be true. Metrics are collected on all users of your website, terabytes of data stored in replicated databases.\n",
    "\n",
    "One day, your boss wants to know if college students are engaging in your website. You pull up the records for users in that age bracket and look at them one by one. The first person only spent half a second on your website before closing the tab — that doesn’t look good. But the second person was on the site for thirty minutes! That’s a running average of 15 minutes site time per user, but you still have half a million records to look at.\n",
    "\n",
    "On top of that, you need to compare it against other age brackets (and the average overall). That’s going to take a lot of time if you do it all by hand, and you’re still not sure what your methodology for proving college students spend enough time on your website to be “engaged”.\n",
    "\n",
    "When conducting data analysis, we want to say something meaningful about our data. Often, we want to know if a change or difference we see in a dataset is “real” or if it’s just a normal fluctuation or a result of the specific sample of people we have chosen to measure. A difference we observe in our data is only important if we can be reasonably sure that it is representative of the population as a whole, and reasonably sure that our result is repeatable.\n",
    "\n",
    "This question of whether a difference is significant or not is essential to making decisions based on that difference. Some instances where this might come up include:\n",
    "\n",
    "* Performing an A/B test — are the different observations really the results of different conditions (i.e., Condition A vs. Condition B)? Or just the result of random chance?\n",
    "\n",
    "* Conducting a survey — is the fact that men gave slightly different responses than women a real difference between men and women? Or just the result of chance?\n",
    "\n",
    "In this lesson, we will cover the fundamental concepts that will help us create tests to measure our confidence in our statistical results:\n",
    "\n",
    "* Sample means and population means\n",
    "* The Central Limit Theorem\n",
    "* Why we use hypothesis tests\n",
    "* What errors we can come across and how to classify them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Mean and Population Mean\n",
    "Suppose you want to know the average height of an oak tree in your local park. On Monday, you measure 10 trees and get an average height of 32 ft. On Tuesday, you measure 12 different trees and reach an average height of 35 ft. On Wednesday, you measure the remaining 11 trees in the park, whose average height is 31 ft. Overall, the average height for all trees in your local park is 32.8 ft.\n",
    "\n",
    "The individual measurements on Monday, Tuesday, and Wednesday are called samples. A sample is a subset of the entire population. The mean of each sample is the sample mean and it is an estimate of the population mean.\n",
    "\n",
    "Note that the sample means (32 ft., 35 ft., and 31 ft.) were all close to the population mean (32.8 ft.), but were all slightly different from the population mean and from each other.\n",
    "\n",
    "For a population, the mean is a constant value no matter how many times it’s recalculated. But with a set of samples, the mean will depend on exactly what samples we happened to choose. From a sample mean, we can then extrapolate the mean of the population as a whole. There are many reasons we might use sampling, such as:\n",
    "\n",
    "* We don’t have data for the whole population.\n",
    "* We have the whole population data, but it is so large that it is infeasible to analyze.\n",
    "* We can provide meaningful answers to questions faster with sampling.\n",
    "\n",
    "When we have a numerical dataset and want to know the average value, we calculate the mean. For a population, the mean is a constant value no matter how many times it’s recalculated. But with a set of samples, the mean will depend on exactly what samples we happened to choose. From a sample mean, we can then extrapolate the mean of the population as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population Mean: 64.93475440939723\n",
      "Sample 1 Mean: 64.30684013794856\n",
      "Sample 2 Mean: 64.55736591886152\n",
      "Sample 3 Mean: 64.79974872794493\n",
      "Sample 4 Mean: 65.373634493646\n",
      "Sample 5 Mean: 64.51634069348326\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "population = np.random.normal(loc=65, scale=3.5, size=300)\n",
    "population_mean = np.mean(population)\n",
    "\n",
    "print(\"Population Mean: {}\".format(population_mean))\n",
    "\n",
    "sample_1 = np.random.choice(population, size=30, replace=False)\n",
    "sample_2 = np.random.choice(population, size=30, replace=False)\n",
    "sample_3 = np.random.choice(population, size=30, replace=False)\n",
    "sample_4 = np.random.choice(population, size=30, replace=False)\n",
    "sample_5 = np.random.choice(population, size=30, replace=False)\n",
    "\n",
    "sample_1_mean = np.mean(sample_1)\n",
    "print (\"Sample 1 Mean: {}\".format(sample_1_mean))\n",
    "\n",
    "sample_2_mean = np.mean(sample_2)\n",
    "sample_3_mean = np.mean(sample_3)\n",
    "sample_4_mean = np.mean(sample_4)\n",
    "sample_5_mean = np.mean(sample_5)\n",
    "\n",
    "print (\"Sample 2 Mean: {}\".format(sample_2_mean))\n",
    "print (\"Sample 3 Mean: {}\".format(sample_3_mean))\n",
    "print (\"Sample 4 Mean: {}\".format(sample_4_mean))\n",
    "print (\"Sample 5 Mean: {}\".format(sample_5_mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Central Limit Theorem\n",
    "Perhaps, this time, you’re a tailor of school uniforms at a middle school. You need to know the average height of people from 10-13 years old in order to know which sizes to make the uniforms. Knowing the best decisions are based on data, you set out to do some research at your local middle school.\n",
    "\n",
    "Organizing with the school, you measure the heights of some students. Their average height is 57.5 inches. You know a little about sampling and decide that measuring 30 out of the 300 students gives enough data to assume 57.5 inches is roughly the average height of everyone at the middle school. You set to work with this dimension and make uniforms that fit people of this height, some smaller and some larger.\n",
    "\n",
    "Unfortunately, when you go about making your uniforms many reports come back saying that they are too small. Something must have gone wrong with your decision-making process! You go back to collect the rest of the data: you measure the sixth graders one day (56.7, not so bad), the seventh graders after that (59 inches tall on average), and the eighth graders the next day (61.7 inches!). Your sample mean was so far off from your population mean. How did this happen?\n",
    "\n",
    "Well, your sample selection was skewed to one direction of the total population. It looks like you must have measured more sixth graders than is representative of the whole middle school. How do you get an average sample height that looks more like the average population height?\n",
    "\n",
    "In the previous exercise, we looked at different sets of samples taken from a population and how the mean of each set could be different from the population mean. This is a natural consequence of the fact that a set of samples has less data than the population to which it belongs. If our sample selection is poor then we will have a sample mean seriously skewed from our population mean.\n",
    "\n",
    "There is one surefire way to mitigate the risk of having a skewed sample mean — take a larger set of samples. The sample mean of a larger sample set will more closely approximate the population mean. This phenomenon, known as the Central Limit Theorem, states that if we have a large enough sample size, all of our sample means will be sufficiently close to the population mean.\n",
    "\n",
    "Later, we’ll learn how to put numeric values on “large enough” and “sufficiently close”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Small Sample Mean: 87.74156497244476\n",
      "Small Sample Mean: 57.137428839048745\n",
      "Medium Sample Mean: 68.19471370415042\n",
      "Large Sample Mean: 74.81674194436796\n",
      "Extra Large Sample Mean: 70.85371926020922\n",
      "Population Mean: 68.33088804365784\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create population and find population mean\n",
    "population = np.random.normal(loc=65, scale=100, size=3000)\n",
    "population_mean = np.mean(population)\n",
    "\n",
    "# Select increasingly larger samples\n",
    "extra_small_sample = population[:10]\n",
    "small_sample = population[:50]\n",
    "medium_sample = population[:100]\n",
    "large_sample = population[:500]\n",
    "extra_large_sample = population[:1000]\n",
    "\n",
    "# Calculate the mean of those samples\n",
    "extra_small_sample_mean = np.mean(extra_small_sample)\n",
    "small_sample_mean =  np.mean(small_sample)\n",
    "medium_sample_mean =  np.mean(medium_sample)\n",
    "large_sample_mean =  np.mean(large_sample)\n",
    "extra_large_sample_mean =  np.mean(extra_large_sample)\n",
    "\n",
    "# Print them all out!\n",
    "print(\"Extra Small Sample Mean: {}\".format(extra_small_sample_mean))\n",
    "print(\"Small Sample Mean: {}\".format(small_sample_mean))\n",
    "print(\"Medium Sample Mean: {}\".format(medium_sample_mean)) \n",
    "print(\"Large Sample Mean: {}\".format(large_sample_mean)) \n",
    "print(\"Extra Large Sample Mean: {}\".format(extra_large_sample_mean)) \n",
    "\n",
    "print(\"Population Mean: {}\".format(population_mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Tests\n",
    "When observing differences in data, a data analyst understands the possibility that these differences could be the result of random chance.\n",
    "\n",
    "Suppose we want to know if men are more likely to sign up for a given programming class than women. We invite 100 men and 100 women to this class. After one week, 34 women sign up, and 39 men sign up. More men than women signed up, but is this a “real” difference?\n",
    "\n",
    "We have taken sample means from two different populations, men and women. We want to know if the difference that we observe in these sample means reflects a difference in the population means. To formally answer this question, we need to re-frame it in terms of probability:\n",
    "\n",
    "“What is the probability that men and women have the same level of interest in this class and that the difference we observed is just chance?”\n",
    "\n",
    "In other words, “If we gave the same invitation to every person in the world, would more men still sign up?”\n",
    "\n",
    "A more formal version is: “What is the probability that the two population means are the same and that the difference we observed in the sample means is just chance?”\n",
    "\n",
    "These statements are all ways of expressing a null hypothesis. A null hypothesis is a statement that the observed difference is the result of chance.\n",
    "\n",
    "Hypothesis testing is a mathematical way of determining whether we can be confident that the null hypothesis is false. Different situations will require different types of hypothesis testing, which we will learn about in the next lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type I Or Type II\n",
    "When we rely on automated processes to make our decisions for us, we need to be aware of how this automation can lead to mistakes. Computer programs are as fallible as the humans who design them. As humans capable of programming, the responsibility is on us to understand what can go wrong and what we can do to contain these foreseeable problems.\n",
    "\n",
    "In statistical hypothesis testing, we concern ourselves primarily with two types of error. The first kind of error, known as a Type I error, is finding a correlation between things that are not related. This error is sometimes called a “false positive” and occurs when the null hypothesis is rejected even though it is true.\n",
    "\n",
    "For example, let’s say you conduct an A/B test for an online store and conclude that interface B is significantly better than interface A at directing traffic to a checkout page. You have rejected the null hypothesis that there is no difference between the two interfaces. If, in reality, your results were due to the groups you happened to pick, and there is actually no significant difference between interface A and interface B in the greater population, you have been the victim of a false positive.\n",
    "\n",
    "The second kind of error, a Type II error, is failing to find a correlation between things that are actually related. This error is referred to as a “false negative” and occurs when the null hypothesis is accepted even though it is false.\n",
    "\n",
    "For example, with the A/B test situation, let’s say that after the test, you concluded that there was no significant difference between interface A and interface B. If there actually is a difference in the population as a whole, your test has resulted in a false negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "In the workspace you will find four lists: actual_positive, actual_negative, experimental_positive, and experimental_negative. These lists represent outcomes from a statistical experiment. Also given is an intersect function that takes two lists as arguments and returns a list of all items in both lists.\n",
    "\n",
    "Examine these lists and make sure you understand what they represent.\n",
    "\n",
    "\n",
    "2.\n",
    "Use the intersect function and the lists provided to define type_i_errors. This list should contain the false positives of the experiment.\n",
    "\n",
    "\n",
    "3.\n",
    "Now, define type_ii_errors, the list representing the false negatives of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 9, 11, 13, 15, 16, 17, 19, 20, 22, 26, 27, 28, 35, 36, 40, 46, 49]\n",
      "[6, 25, 29, 30, 33, 42, 44, 47]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def intersect(list1, list2):\n",
    "  return [sample for sample in list1 if sample in list2]\n",
    "\n",
    "# the true positives and negatives:\n",
    "actual_positive = [2, 5, 6, 7, 8, 10, 18, 21, 24, 25, 29, 30, 32, 33, 38, 39, 42, 44, 45, 47]\n",
    "\n",
    "actual_negative = [1, 3, 4, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 26, 27, 28, 31, 34, 35, 36, 37, 40, 41, 43, 46, 48, 49]\n",
    "\n",
    "# the positives and negatives we determine by running the experiment:\n",
    "experimental_positive = [2, 4, 5, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 32, 35, 36, 38, 39, 40, 45, 46, 49]\n",
    "\n",
    "experimental_negative = [1, 3, 6, 12, 14, 23, 25, 29, 30, 31, 33, 34, 37, 41, 42, 43, 44, 47, 48]\n",
    "\n",
    "#define type_i_errors and type_ii_errors here\n",
    "type_i_errors = intersect(experimental_positive, actual_negative)\n",
    "type_ii_errors = intersect(experimental_negative, actual_positive)\n",
    "\n",
    "print(type_i_errors)\n",
    "print(type_ii_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P-Values\n",
    "We have discussed how a hypothesis test is used to determine the validity of a null hypothesis. A hypothesis test provides a numerical answer, called a p-value, that helps us decide how confident we can be in the result. In this context, a p-value is the probability that we yield the observed statistics under the assumption that the null hypothesis is true.\n",
    "\n",
    "A p-value of 0.05 would mean that if we assume the null hypothesis is true, there is a 5% chance that the data results in what was observed due only to random sampling error. This generally means there is a 5% chance that there is no difference between the two population means.\n",
    "\n",
    "Before conducting a hypothesis test, we determine the necessary threshold we would need before concluding that the results are significant. A higher p-value is more likely to give a false positive so if we want to be very sure that the result is not due to just chance, we will select a very small p-value.\n",
    "\n",
    "It is important that we choose the significance level before we perform our statistical hypothesis tests to yield a p-value. If we wait until after we see the results, we might pick our threshold such that we get the result we want to see. For instance, if we’re trying to publish our results, we might set a significance level that makes our results seem statistically significant. Choosing our significance level in advance helps keep us honest.\n",
    "\n",
    "Generally, we want a p-value of less than 0.05, meaning that there is less than a 5% chance that our results are due to random chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "given function reject_null_hypothesis to return True if the p-value is small enough that the data is significant (i.e., it’s less than 0.05), and return False if the p-value is large enough that the data is not likely to be significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def reject_null_hypothesis(p_value):\n",
    "\n",
    "  \"\"\"\n",
    "  Returns the truthiness of whether the null hypothesis can be rejected\n",
    "\n",
    "  Takes a p-value as its input and assumes p <= 0.05 is significant\n",
    "  \"\"\"\n",
    "  if p_value < 0.05:\n",
    "    return True\n",
    "  return False \n",
    "\n",
    "hypothesis_tests = [0.1, 0.009, 0.051, 0.012, 0.37, 0.6, 0.11, 0.025, 0.0499, 0.0001]\n",
    "\n",
    "for p_value in hypothesis_tests:\n",
    "    print(reject_null_hypothesis(p_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Sample T-Testing\n",
    "Let’s imagine the fictional business BuyPie, which sends ingredients for pies to your household, so that you can make them from scratch. Suppose that a product manager wants the average age of visitors to BuyPie.com to be 30. In the past hour, the website had 100 visitors and the average age was 31. Are the visitors too old? Or is this just the result of chance and a small sample size?\n",
    "\n",
    "We can test this using a univariate T-test. A univariate T-test compares a sample mean to a hypothetical population mean. It answers the question “What is the probability that the sample came from a distribution with the desired mean?”\n",
    "\n",
    "When we conduct a hypothesis test, we want to first create a null hypothesis, which is a prediction that there is no significant difference. The null hypothesis that this test examines can be phrased as such: “The set of samples belongs to a population with the target mean”.\n",
    "\n",
    "The result of the 1 Sample T Test is a p-value, which will tell us whether or not we can reject this null hypothesis. Generally, if we receive a p-value of less than 0.05, we can reject the null hypothesis and state that there is a significant difference.\n",
    "\n",
    "SciPy has a function called ttest_1samp, which performs a 1 Sample T-Test for you.\n",
    "\n",
    "ttest_1samp requires two inputs, a distribution of values and an expected mean:\n",
    "\n",
    "    tstat, pval = ttest_1samp(example_distribution, expected_mean)\n",
    "    print(pval)\n",
    "    \n",
    "It also returns two outputs: the t-statistic (which we won’t cover in this course), and the p-value — telling us how confident we can be that the sample of values came from a distribution with the mean specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "We have provided a small dataset called ages, representing the ages of customers to BuyPie.com in the past hour.\n",
    "\n",
    "First, print out ages to the console and examine the numbers.\n",
    "\n",
    "\n",
    "2.\n",
    "Even with a small dataset like this, it is hard to make judgments from just looking at the numbers.\n",
    "\n",
    "To understand the data better, let’s look at the mean. Calculate the mean of ages using np.mean. Store it in a variable called ages_mean and print it out.\n",
    "\n",
    "\n",
    "3.\n",
    "Use ttest_1samp with ages to see what p-value the experiment returns for this distribution, where we expect the mean to be 30.\n",
    "\n",
    "Store the p-value in a variable called pval. Remember that it is the second output of the ttest_1samp function. We don’t use the first output, the t-statistic, so you can store it in a variable with whatever name you’d like.\n",
    "\n",
    "\n",
    "4.\n",
    "Print out pval to the console. Does the p-value you got with the 1 Sample T-Test make sense, knowing the mean of ages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.0\n",
      "0.5605155888171379\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "import numpy as np\n",
    "\n",
    "ages = [ 32,  34, 29,  29,  22,  39,  38,  37,  38,  36,  30,  26,  22,  22]\n",
    "\n",
    "\n",
    "\n",
    "ages_mean = np.mean(ages)\n",
    "\n",
    "print(ages_mean)\n",
    "tset, pval = ttest_1samp(ages, 30)\n",
    "\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Sample T-Test II\n",
    "In the last exercise, we got a p-value that was much higher than 0.05, so we cannot reject the null hypothesis. Does this mean that if we wait for more visitors to BuyPie, the average age would definitely be 30 and not 31? Not necessarily. In fact, in this case, we know that the mean of our sample was 31.\n",
    "\n",
    "P-values give us an idea of how confident we can be in a result. Just because we don’t have enough data to detect a difference doesn’t mean that there isn’t one. Generally, the more samples we have, the smaller a difference we’ll be able to detect. You can learn more about the exact relationship between the number of samples and detectable differences in the Sample Size Determination course.\n",
    "\n",
    "To gain some intuition on how our confidence levels can change, let’s explore some distributions with different means and how our p-values from the 1 Sample T-Tests change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "We have loaded a dataset daily_visitors into the editor that represents the ages of visitors to BuyPie.com in the last 1000 days. Each entry daily_visitors[i] is an array of entries representing the age per visitor to the website on day i.\n",
    "\n",
    "We predicted that the average age would be 30, and we want to know if the actual data differs from that.\n",
    "\n",
    "We have made a for loop that goes through the 1000 inner lists. Inside this loop, perform a 1 Sample T-Test with each day of data (daily_visitors[i]). For now, just print out the p-value from each test.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2.\n",
    "If we get a pval < 0.05, we can conclude that it is unlikely that our sample has a true mean of 30. Thus, the hypothesis test has correctly rejected the null hypothesis, and we call that a correct result.\n",
    "\n",
    "Every time we get a correct result within the 1000 experiments, add 1 to correct_results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23695942473632142\n",
      "0.005511750046377255\n",
      "0.23636795865412213\n",
      "0.10783517811607937\n",
      "0.004414882120780694\n",
      "0.16214048205543172\n",
      "0.1600829236665709\n",
      "0.008752908031478393\n",
      "0.009413759844110177\n",
      "0.28829862847381077\n",
      "0.035310467589078576\n",
      "0.2144769257585793\n",
      "0.0006227718256323399\n",
      "9.588258876957111e-06\n",
      "0.23515092297509535\n",
      "0.00026342324862845364\n",
      "0.8039284954571189\n",
      "0.030165739305163603\n",
      "0.6706988618319033\n",
      "0.08734286055124148\n",
      "2.907880833989432e-05\n",
      "0.02649255683160421\n",
      "0.04467245164993898\n",
      "0.13544331926124387\n",
      "0.016612898432082093\n",
      "0.14892019305948018\n",
      "0.037645152288740394\n",
      "0.015376369766211437\n",
      "0.15679877794158653\n",
      "0.15065054103948747\n",
      "0.0685476997160581\n",
      "0.14946579127226753\n",
      "0.00035270120578793457\n",
      "0.011641901238399317\n",
      "0.7993493159918439\n",
      "0.01625350692456645\n",
      "0.0271314568134415\n",
      "0.04835788738829874\n",
      "0.11758287850526042\n",
      "0.8801423342575648\n",
      "0.05547696429556022\n",
      "0.005089847690879995\n",
      "0.006679724618281934\n",
      "0.12478644532611288\n",
      "0.00373992490997133\n",
      "0.0016715530036133515\n",
      "0.0012944771181846912\n",
      "0.153507674004558\n",
      "0.7798467721041478\n",
      "0.008576410193874198\n",
      "0.5027106571412492\n",
      "0.04422914470390454\n",
      "0.0009039396716674654\n",
      "0.886965065712008\n",
      "0.3251564469020599\n",
      "0.004574205409497792\n",
      "0.004072773108335167\n",
      "0.02910311950541742\n",
      "0.0030699334740924705\n",
      "0.009583060014908383\n",
      "0.02649255683160415\n",
      "0.014668481218483324\n",
      "0.0293111888215088\n",
      "0.00060515794972876\n",
      "4.230587611268207e-05\n",
      "0.3495019334205012\n",
      "0.14940144423777202\n",
      "0.16624596534051206\n",
      "0.003274329671169529\n",
      "0.42217775653327405\n",
      "0.05971917338615492\n",
      "0.003239965431140473\n",
      "0.11270391373734587\n",
      "0.5101042993348434\n",
      "0.6467288614415618\n",
      "0.0962899868137176\n",
      "0.0563254067626493\n",
      "0.036977314173032336\n",
      "0.15947362192588682\n",
      "0.00021990104756833216\n",
      "0.0013922758393482386\n",
      "0.17055983293347715\n",
      "0.04074250405825499\n",
      "0.03340735404617234\n",
      "0.2173963980749399\n",
      "0.5162461208076692\n",
      "0.05111546404785682\n",
      "0.04251928171293055\n",
      "0.09705785423460352\n",
      "0.9255334690035302\n",
      "0.07601614060659455\n",
      "0.030048491165037165\n",
      "1.5821675677027197e-05\n",
      "0.10204606475885365\n",
      "0.27600982066445573\n",
      "0.18436484435010203\n",
      "0.0003366151567115432\n",
      "0.04065543101088513\n",
      "0.041646067468649864\n",
      "0.35212486009956845\n",
      "0.6632430382863247\n",
      "0.0008159769897960798\n",
      "0.0007341350802828997\n",
      "0.06532171843923693\n",
      "0.2115964274552412\n",
      "0.12191603550161566\n",
      "0.08880969399629852\n",
      "0.007284637609965174\n",
      "0.00023866050458337234\n",
      "0.0011441131476259267\n",
      "0.15408164725037224\n",
      "0.013735454852300495\n",
      "0.0006683890521511181\n",
      "0.018732176856619105\n",
      "0.05410480099142027\n",
      "0.0735245296045807\n",
      "0.042425852951127836\n",
      "0.004879876083853939\n",
      "0.13755080197352693\n",
      "0.07290468350043462\n",
      "0.06672065764932955\n",
      "0.0034960207408092007\n",
      "0.013042659487673185\n",
      "0.004446935976171634\n",
      "0.020355692485180866\n",
      "0.003790200501592761\n",
      "0.004612827109189205\n",
      "0.0597418783085019\n",
      "0.44564355795758537\n",
      "0.3693331138369136\n",
      "0.012568701765151563\n",
      "0.013709125334384191\n",
      "0.06381243200181666\n",
      "0.007772479582404979\n",
      "0.0009166553151043526\n",
      "0.12396194834043026\n",
      "0.19341636971820986\n",
      "0.0014839485260318374\n",
      "0.030527476351859036\n",
      "0.0023853375347269337\n",
      "0.005158305094115377\n",
      "0.01873111289960567\n",
      "3.913761437933197e-05\n",
      "0.005775079712454813\n",
      "0.17611785985826048\n",
      "0.03327426842350145\n",
      "0.2124506208512219\n",
      "0.03205421141258727\n",
      "0.05167247134971531\n",
      "0.36879146757173253\n",
      "0.006593362361320948\n",
      "0.007615330343840694\n",
      "0.01783295721231968\n",
      "0.036968240063492634\n",
      "0.20776087941522609\n",
      "0.018817633411758374\n",
      "0.010268670223025111\n",
      "0.03081002775509486\n",
      "0.09897390920825262\n",
      "0.15774784284677706\n",
      "0.1979593950184332\n",
      "0.32986258410002545\n",
      "0.00019466244638073399\n",
      "0.011230818055365776\n",
      "0.0014946485843384176\n",
      "0.1371011777162396\n",
      "0.01930328346497477\n",
      "0.013016456038181428\n",
      "0.3399969906569187\n",
      "0.13838889707555185\n",
      "0.012584571658224731\n",
      "0.10931008717907727\n",
      "0.16953610750314174\n",
      "8.288643960967198e-06\n",
      "0.11465014255191716\n",
      "0.004627963997673421\n",
      "0.09636976949242913\n",
      "0.3720573203919343\n",
      "0.006356212606098133\n",
      "0.24829025594596446\n",
      "0.5970490799987067\n",
      "0.4598449844008855\n",
      "0.1739664308574969\n",
      "0.039881284760178964\n",
      "0.0010595346184473786\n",
      "0.00040609066701407853\n",
      "0.02523669649117434\n",
      "0.0003841071319669985\n",
      "0.009649872171444283\n",
      "0.03428944516828292\n",
      "0.14036714669908348\n",
      "0.4410252468438358\n",
      "0.061565356636597166\n",
      "0.052489199461249\n",
      "6.908575341201987e-05\n",
      "0.0006326818424674946\n",
      "0.04784781796876228\n",
      "0.012334460875348936\n",
      "0.001653593766971067\n",
      "0.00026557439743159423\n",
      "3.8303337006385006e-05\n",
      "0.0420685543171256\n",
      "0.01755491526203616\n",
      "0.07440926022229408\n",
      "0.04823686316604168\n",
      "0.05600779048720743\n",
      "0.13849917647545174\n",
      "0.04271873127229392\n",
      "0.01569796700238894\n",
      "0.32886776952560226\n",
      "0.004551565549198842\n",
      "0.9020227711337483\n",
      "0.1591238646884132\n",
      "0.021953842308910097\n",
      "1.0353775721614028e-06\n",
      "0.667686361467181\n",
      "0.40847961735165117\n",
      "0.09004864398864612\n",
      "0.05249380463388844\n",
      "5.666609387460821e-05\n",
      "0.0002586725329523724\n",
      "0.00013023497264181766\n",
      "0.0015154945813685879\n",
      "0.0032788948737351034\n",
      "0.09388876875331795\n",
      "0.19458052493137418\n",
      "1.0\n",
      "0.0017013844499965318\n",
      "0.012029424243113937\n",
      "0.09874821399035025\n",
      "0.06054312319851129\n",
      "0.00023238222148408866\n",
      "0.04802437240917031\n",
      "0.014369077642653562\n",
      "0.009374619024820646\n",
      "0.004372420501780707\n",
      "0.1367187085628594\n",
      "0.49230518667613\n",
      "0.010784568223133938\n",
      "0.0950659416661259\n",
      "0.09952691877564453\n",
      "0.44072630903945587\n",
      "0.0021024994699193615\n",
      "0.0692838800307604\n",
      "0.10379998857850047\n",
      "0.03485520968324601\n",
      "0.038025093402752855\n",
      "0.0033782964491633704\n",
      "0.5289454191411362\n",
      "0.0003844232211004813\n",
      "0.10927129031096455\n",
      "0.07673195274216656\n",
      "0.0037615932232890246\n",
      "0.0025003749537470996\n",
      "0.006328654073962432\n",
      "0.0023828833103535507\n",
      "0.7573269129890847\n",
      "0.006738326747625833\n",
      "0.36095035604354264\n",
      "0.1416145089360793\n",
      "0.09527477430762302\n",
      "0.5903003370119702\n",
      "0.026582938931324143\n",
      "0.0654808075704019\n",
      "0.01717145650260221\n",
      "0.3045330004109541\n",
      "0.12164128117012322\n",
      "0.19743699717623395\n",
      "0.01926852692921612\n",
      "0.488746972274247\n",
      "0.6721086372536793\n",
      "0.9666356950628876\n",
      "0.001583326295258411\n",
      "0.05426830581085041\n",
      "0.3176491705281351\n",
      "0.020721707283688075\n",
      "0.05840207329090649\n",
      "0.029435683343830628\n",
      "0.001029013090503309\n",
      "0.016465624733464242\n",
      "7.731665536654897e-05\n",
      "0.054412142634041184\n",
      "0.3300770309100203\n",
      "0.1302455762192448\n",
      "0.13536360520973043\n",
      "0.0888593665480137\n",
      "0.06756740468175329\n",
      "0.11499958206521779\n",
      "0.017875398584003797\n",
      "0.09413563039218073\n",
      "0.060840236766787396\n",
      "0.05225585630873309\n",
      "0.04535356799601371\n",
      "0.030002818322672466\n",
      "0.11955258922439056\n",
      "0.25911987016131505\n",
      "0.0066039136692290544\n",
      "0.4707045704714853\n",
      "0.006243676903936663\n",
      "0.3980184426001051\n",
      "0.2480745768574467\n",
      "0.2198803744257107\n",
      "0.11029382161909788\n",
      "9.559619189534762e-05\n",
      "0.6830533213169802\n",
      "0.5960411937574444\n",
      "0.4193068044065402\n",
      "0.009642673619854967\n",
      "0.03562284599675621\n",
      "0.018730082950794674\n",
      "0.8762518714547024\n",
      "0.022715625262268037\n",
      "0.000431610624679815\n",
      "0.04305959235718929\n",
      "0.08879727981902347\n",
      "0.0032714462432508265\n",
      "0.004138881079487707\n",
      "0.0007706273286476353\n",
      "0.008925124033041345\n",
      "0.01542566599397203\n",
      "0.3283468403325823\n",
      "0.0055549446801250475\n",
      "0.0006865449525788666\n",
      "0.671080099814464\n",
      "0.005769009999541039\n",
      "0.01834419099749824\n",
      "0.0195834137534618\n",
      "0.03465118209118181\n",
      "0.5918048489174642\n",
      "0.01048611890093617\n",
      "0.2535349128239082\n",
      "0.031054711485233644\n",
      "3.0418379398868793e-05\n",
      "0.029869346129380046\n",
      "0.008631757162003657\n",
      "0.0003326988732533245\n",
      "0.013839346727835372\n",
      "0.07205970175582681\n",
      "0.043568426306066416\n",
      "0.007604448949605506\n",
      "0.025107369096205034\n",
      "0.05793458440463086\n",
      "0.09111257532088239\n",
      "0.14292756409547425\n",
      "0.12008844647788665\n",
      "2.9054073957167223e-05\n",
      "0.3277785338564888\n",
      "0.11107745733041062\n",
      "0.004769908297587897\n",
      "1.98203494625316e-06\n",
      "0.08376244742866043\n",
      "0.001024491421377399\n",
      "0.02162319384120594\n",
      "0.18055225728504207\n",
      "0.32532504317129196\n",
      "0.003529927296697593\n",
      "0.7665244085804985\n",
      "0.026786077764785286\n",
      "0.24068095799429734\n",
      "0.00016216176691717\n",
      "0.48127394303189885\n",
      "0.02197794251419929\n",
      "0.06240124808474423\n",
      "0.04388636353868672\n",
      "0.06008469241603428\n",
      "0.013696664111999808\n",
      "0.40941561791283543\n",
      "0.004625280559208805\n",
      "0.0002820867861767529\n",
      "0.0012203202332489876\n",
      "0.14571802929318983\n",
      "0.030281693823262432\n",
      "0.506996596860727\n",
      "0.02430735064807672\n",
      "0.00031702442886075497\n",
      "0.03542300014070489\n",
      "0.48226247077230877\n",
      "0.1185157293811455\n",
      "0.012220244100738034\n",
      "0.5378733316116032\n",
      "0.16246443254822374\n",
      "0.31622094584951005\n",
      "0.06998578446790814\n",
      "1.479082925545653e-05\n",
      "0.10164741562707995\n",
      "0.028282183766075122\n",
      "0.011409656447467149\n",
      "0.06380588556625186\n",
      "0.010296792839128573\n",
      "0.14271190259336616\n",
      "0.04119343061830363\n",
      "0.1611734256986564\n",
      "0.005849210939381234\n",
      "0.2626344532342644\n",
      "0.91223147171371\n",
      "0.3834336301475463\n",
      "0.06411519008579449\n",
      "0.017820435001373938\n",
      "0.14977091668949036\n",
      "0.17166278883637479\n",
      "0.4341128895849725\n",
      "0.07984990679385187\n",
      "0.13993495070860967\n",
      "0.13208513759571175\n",
      "0.024886519224949003\n",
      "0.033140994379256494\n",
      "0.028213139672556314\n",
      "0.03262449608030923\n",
      "0.001084989004484974\n",
      "0.013095229764144057\n",
      "0.3860579040974953\n",
      "0.007294432350754174\n",
      "0.1176463754376966\n",
      "0.08883086595508505\n",
      "0.00801001191028735\n",
      "0.03238290602537596\n",
      "0.17837796826039054\n",
      "0.13403333757962774\n",
      "0.09501263262942912\n",
      "0.01331384370489222\n",
      "0.018996292830400736\n",
      "0.0018495779811424752\n",
      "0.007462432778595462\n",
      "0.1916460438000275\n",
      "0.07611871762284156\n",
      "0.07710606586449512\n",
      "0.43111154871011903\n",
      "6.946817006740601e-06\n",
      "0.000432305279508967\n",
      "0.002087402033469929\n",
      "0.021884323578046757\n",
      "0.14171940114631515\n",
      "0.3389433038135182\n",
      "0.486171441099967\n",
      "0.0030561529937322683\n",
      "0.0634921683778847\n",
      "0.16842796738143495\n",
      "0.0414632620723399\n",
      "0.052809732931760084\n",
      "0.06891639158028995\n",
      "0.003895014849385125\n",
      "0.026528073223072532\n",
      "0.07535250448015862\n",
      "0.07122327117942487\n",
      "0.13519487976448785\n",
      "0.007579830720853679\n",
      "0.10562012108233956\n",
      "0.4119655570461608\n",
      "0.0713019251230752\n",
      "0.004492572959961375\n",
      "0.006265459520760706\n",
      "0.10490714620010683\n",
      "0.9058670244709409\n",
      "0.7505066976554049\n",
      "0.008566434659880742\n",
      "0.6508776159874932\n",
      "0.039620444039725734\n",
      "0.19637584926653548\n",
      "0.1314586804461182\n",
      "0.11341632000326297\n",
      "0.000338099133481912\n",
      "0.1274589797990574\n",
      "0.06367059714959325\n",
      "0.044094902583069466\n",
      "0.048590700182539595\n",
      "0.002436812356628597\n",
      "0.21477952048945687\n",
      "0.0767950487628689\n",
      "0.0018196910000344046\n",
      "0.010180366137389141\n",
      "0.29000363344095104\n",
      "0.0372714445723211\n",
      "0.23995419337899687\n",
      "0.077716987865983\n",
      "0.005791207879624332\n",
      "0.004685277967068269\n",
      "0.02208978053899039\n",
      "0.02925756458469964\n",
      "0.47889991357378014\n",
      "0.024756613793116805\n",
      "0.02832976813924925\n",
      "0.016575830102447973\n",
      "0.06979877779797171\n",
      "0.16307190520505277\n",
      "0.011117407437792848\n",
      "0.48127394303189885\n",
      "0.00011691858007014855\n",
      "0.24105019290643628\n",
      "0.001638610187994947\n",
      "0.02266118916229611\n",
      "0.012065071029855767\n",
      "0.2094038705711786\n",
      "0.11852758352612724\n",
      "0.11897672347535451\n",
      "0.15103572193923662\n",
      "0.051284516488522246\n",
      "0.732999910469222\n",
      "0.21805161068948084\n",
      "0.04136717593518929\n",
      "0.13898115239882308\n",
      "0.00027890035748783323\n",
      "0.017076289559248368\n",
      "0.024078239409584555\n",
      "0.29977148018853367\n",
      "0.02332331541370856\n",
      "0.9692880189207581\n",
      "2.4227855367520034e-06\n",
      "0.09084580988668779\n",
      "0.003218880956704788\n",
      "0.12083167189348527\n",
      "0.00011387071197163827\n",
      "0.007994959183873135\n",
      "0.07097864097046269\n",
      "0.3274160475445186\n",
      "0.024514319926772186\n",
      "0.00804073247119753\n",
      "0.0006154682722302537\n",
      "0.5503690225228037\n",
      "0.1471007974142805\n",
      "8.150215722741611e-05\n",
      "0.22188216615972797\n",
      "0.787007917969865\n",
      "0.13489191821607127\n",
      "0.21840640560184515\n",
      "0.050895848058666225\n",
      "0.0606800444782928\n",
      "0.009073114599238964\n",
      "0.004766173825518688\n",
      "0.26043009821210567\n",
      "0.009523067465336621\n",
      "0.003893519803957657\n",
      "0.43419833691091747\n",
      "0.011915942821265726\n",
      "0.009581377329849719\n",
      "0.016971682518626404\n",
      "0.00515564661887572\n",
      "0.16509503185246543\n",
      "0.008814866138014738\n",
      "0.023151612807881895\n",
      "0.00017941117905770793\n",
      "0.023928513204737985\n",
      "0.01625350692456645\n",
      "0.06534447701220857\n",
      "0.020239595581465455\n",
      "0.07276462131501236\n",
      "0.0017250483675539767\n",
      "0.1733580059685621\n",
      "0.052139426717674464\n",
      "0.21779553075561564\n",
      "0.4053607106241913\n",
      "0.018425520769872195\n",
      "0.13247317615441326\n",
      "0.24319061237227685\n",
      "0.3181870389698565\n",
      "0.030855154745303433\n",
      "0.017158339463717177\n",
      "0.0035448392575030928\n",
      "0.0006295821713657631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01404700365518679\n",
      "0.01731313427959406\n",
      "0.0003193460314599023\n",
      "0.000641872680652316\n",
      "0.11778648817299306\n",
      "0.024613411631637813\n",
      "0.08101514124785011\n",
      "0.0028801862401371704\n",
      "0.0008468147787030149\n",
      "0.249831853694697\n",
      "0.07617944729588168\n",
      "0.23195920017043778\n",
      "0.04466798799496514\n",
      "0.2694622736245003\n",
      "0.7575592269788329\n",
      "0.04789708089816328\n",
      "0.030062180861750318\n",
      "0.0822750325881097\n",
      "0.13940847177552915\n",
      "0.0010839890711375271\n",
      "0.015586268581441458\n",
      "0.02040612241578585\n",
      "0.0675813719930734\n",
      "0.008847414039087764\n",
      "0.9707376281247637\n",
      "0.07795892064211805\n",
      "0.0013187690349869777\n",
      "0.4501686382933525\n",
      "0.007337396615744979\n",
      "0.364168672353419\n",
      "0.001715137152932233\n",
      "0.006324684047292254\n",
      "0.0015407060415340912\n",
      "0.03857306413680236\n",
      "0.46937366920902124\n",
      "0.00012500200939840838\n",
      "0.023890616725610093\n",
      "0.18544953833289293\n",
      "0.014474765335674267\n",
      "0.8897711187306735\n",
      "0.039388465447067283\n",
      "0.0006925766471489146\n",
      "0.2599146639401117\n",
      "0.056963231877572254\n",
      "0.046594765461184594\n",
      "0.09654228146531799\n",
      "0.2800716903072255\n",
      "0.0528477218435171\n",
      "0.35213708449456693\n",
      "0.9533909668877849\n",
      "0.017690642674688995\n",
      "0.5487666066359633\n",
      "0.0012751882536924017\n",
      "0.00021029358141889994\n",
      "0.5931337561857741\n",
      "0.2508066204772156\n",
      "0.07981678084801187\n",
      "3.6572451104315736e-07\n",
      "0.04299749101305178\n",
      "0.014287547978372287\n",
      "0.033745410519225374\n",
      "0.366657157285199\n",
      "0.07187433409859788\n",
      "0.37671139713330226\n",
      "0.26433468343370037\n",
      "0.33591500359044635\n",
      "0.45010413817495176\n",
      "0.05468304100367214\n",
      "0.41287203806287254\n",
      "0.04804141141780302\n",
      "0.03155775092178941\n",
      "0.014669893129136052\n",
      "0.12284702076742376\n",
      "1.683575078926328e-05\n",
      "0.30386986379920355\n",
      "0.00016369231489743384\n",
      "0.5126696810216005\n",
      "0.07497842962673087\n",
      "0.014734913474104997\n",
      "0.0010860504367711807\n",
      "0.2959390096105604\n",
      "0.005642946813886422\n",
      "0.23621385793739505\n",
      "0.07129217312228732\n",
      "0.07231465268531442\n",
      "0.03914872600056027\n",
      "0.0004987794854558563\n",
      "0.014547224318857608\n",
      "0.01203285036205843\n",
      "0.7277812497989122\n",
      "0.006396749240842237\n",
      "0.25139513651214357\n",
      "0.033499300837475314\n",
      "0.41910358204551235\n",
      "0.025926587007298465\n",
      "0.17663191430806705\n",
      "0.012165769543734925\n",
      "0.37572109603878856\n",
      "0.2944175806292482\n",
      "0.3164602479623468\n",
      "0.2977224851827333\n",
      "0.0039863109858580305\n",
      "1.9391479076044234e-05\n",
      "0.004595519029696402\n",
      "0.006214998034801783\n",
      "0.19087030498836371\n",
      "2.423710643461597e-05\n",
      "0.3502708104023726\n",
      "0.04230345287444168\n",
      "0.001620349167539596\n",
      "0.13775915664543442\n",
      "0.4089544507853915\n",
      "2.442812263269343e-05\n",
      "0.01236272736437647\n",
      "0.04002859911235183\n",
      "0.061231392494594264\n",
      "0.4571070411629933\n",
      "0.12162724820947025\n",
      "0.09680962676337491\n",
      "0.4150630367286352\n",
      "0.22201641931735733\n",
      "0.09118531843051444\n",
      "0.17610018228882784\n",
      "0.04425804496036115\n",
      "0.12907386294599354\n",
      "0.006079057570111355\n",
      "0.1684114171702944\n",
      "0.7023671048725943\n",
      "0.0009193478989617364\n",
      "0.01024841315121041\n",
      "0.07308516876219322\n",
      "0.009387545123339011\n",
      "2.6176649224666856e-05\n",
      "0.15339631402184467\n",
      "0.2931080611105107\n",
      "9.62743412039052e-06\n",
      "0.030320984567490838\n",
      "0.19122299845183147\n",
      "0.0026422334649983336\n",
      "0.009147698232131619\n",
      "0.020873021715544466\n",
      "0.7365787416799672\n",
      "0.04795561794820603\n",
      "0.0055849660780615444\n",
      "0.09677903116380476\n",
      "0.21157280730005318\n",
      "0.004836037901469394\n",
      "0.040389712110806525\n",
      "0.048541705983033506\n",
      "0.11022566295391727\n",
      "0.01194345783574373\n",
      "0.538584578817235\n",
      "0.07067455465002997\n",
      "3.391550316555636e-06\n",
      "0.3822213696700144\n",
      "0.10137280574847828\n",
      "0.013242742922211627\n",
      "0.02774354641356252\n",
      "0.0013427592014305292\n",
      "0.834978676372062\n",
      "0.0011808456110992567\n",
      "0.0829007627159412\n",
      "0.5139004249283778\n",
      "0.1684975077180742\n",
      "0.34207456404309\n",
      "0.004407529378742711\n",
      "0.0010722365206524947\n",
      "0.010812174405798599\n",
      "0.0007500063944874721\n",
      "0.3253544105804026\n",
      "0.18253231810002954\n",
      "0.03310064225932719\n",
      "0.006661252946575391\n",
      "0.015705050251087864\n",
      "0.14089991753559838\n",
      "0.14159692041047373\n",
      "0.005498743351500244\n",
      "0.3592214595655595\n",
      "0.3884924207570635\n",
      "0.011147883730876936\n",
      "0.8020289669078925\n",
      "0.08886525074908354\n",
      "0.017094341786316723\n",
      "0.4572172085878742\n",
      "0.5567003104007107\n",
      "0.9149464911998593\n",
      "0.22643752770644185\n",
      "0.12093661399783058\n",
      "0.21211936606504214\n",
      "0.030597151475057063\n",
      "0.12526151392192106\n",
      "0.8500923448425859\n",
      "0.8450697343719605\n",
      "0.03991675292451567\n",
      "0.3199509592449805\n",
      "0.021526027326505295\n",
      "0.02629549043514686\n",
      "0.7193838299160202\n",
      "0.05618784653444933\n",
      "0.0581856760873616\n",
      "0.11751933394823869\n",
      "0.000507729441776446\n",
      "0.12771334591269726\n",
      "0.09582673189618622\n",
      "0.006026412279986732\n",
      "0.009447125051404267\n",
      "0.0636783956875056\n",
      "0.16155149369147428\n",
      "0.01741399878193458\n",
      "4.837471130577045e-05\n",
      "0.00023656698900822266\n",
      "0.15053280473494718\n",
      "0.012964692838323164\n",
      "0.08860158909307585\n",
      "0.01787819222042333\n",
      "0.5357258597074719\n",
      "0.4918200787212952\n",
      "0.0011842410298837547\n",
      "0.39208357076600087\n",
      "0.14021857216914949\n",
      "0.0006441584445688022\n",
      "0.4892565466678871\n",
      "0.06603218851934034\n",
      "0.2134610499742672\n",
      "5.264798670557805e-05\n",
      "0.004456926984379088\n",
      "0.004368102723025057\n",
      "0.09392650925103219\n",
      "0.01867082012037702\n",
      "0.002435164108915462\n",
      "0.034923126867060644\n",
      "0.18720180502794068\n",
      "0.08465320250115739\n",
      "0.05472869303551281\n",
      "0.8667165301917297\n",
      "8.795581839587769e-05\n",
      "0.043159337264616265\n",
      "0.01058727103189691\n",
      "0.12541240521279517\n",
      "0.659868865377609\n",
      "0.12693563154343387\n",
      "0.05642856271243614\n",
      "0.20245659086611797\n",
      "0.047512695888581945\n",
      "0.008625170340867894\n",
      "0.7991871581181087\n",
      "0.013660650746632022\n",
      "0.014414560938872056\n",
      "0.16076158777249147\n",
      "0.3780312588085587\n",
      "0.009273065998125923\n",
      "0.36968001858191\n",
      "0.02422174778560124\n",
      "0.023273958719651003\n",
      "0.17462771188395085\n",
      "0.5080903806688046\n",
      "0.03476838623771603\n",
      "0.0024390308713033515\n",
      "0.03714203804473239\n",
      "0.0908191114546531\n",
      "0.42977570896149464\n",
      "0.0014674815282063303\n",
      "0.008871042361293189\n",
      "0.05195663849363792\n",
      "0.0016300291900583578\n",
      "0.05192828014115552\n",
      "0.03436494640276766\n",
      "0.32620550312747143\n",
      "0.14410192039643743\n",
      "0.5921461077406857\n",
      "0.2456186677369067\n",
      "0.2628269985368306\n",
      "0.0004978828437450677\n",
      "0.054257908130479995\n",
      "0.27885660404350526\n",
      "0.22319049392979123\n",
      "0.01093762134821655\n",
      "0.002266339978931187\n",
      "0.0022371495154886543\n",
      "0.5806767888148512\n",
      "0.017731662425921956\n",
      "0.4253307345538445\n",
      "0.006187554601536605\n",
      "0.1848252970926764\n",
      "0.059068130346002376\n",
      "0.30453040080979576\n",
      "0.9001976706961008\n",
      "0.037440365539296895\n",
      "0.0013391781538014728\n",
      "0.6256676378927347\n",
      "0.1552398606263412\n",
      "0.00016998890879787779\n",
      "0.1085417229023679\n",
      "0.0011170465170635168\n",
      "0.0007737011084607557\n",
      "0.16156282362026705\n",
      "0.029116916174228097\n",
      "0.0364212432111863\n",
      "0.05846710727831822\n",
      "0.0025268041546313725\n",
      "0.009834699875935049\n",
      "0.023737761768635877\n",
      "0.3723923176325392\n",
      "0.017290944281008653\n",
      "4.1476856331304464e-05\n",
      "0.5791215864370689\n",
      "0.4148459693995077\n",
      "0.05933483124928568\n",
      "0.00959738082293534\n",
      "0.002429629979650248\n",
      "0.07542348064577276\n",
      "0.24602330373620324\n",
      "0.4857941597507165\n",
      "0.008792343808282343\n",
      "0.5810831838756756\n",
      "0.021114904390651345\n",
      "0.006274811781082217\n",
      "0.06745406578382171\n",
      "0.014190701002785503\n",
      "0.09773865434244938\n",
      "0.005429312197087601\n",
      "0.000260433608933623\n",
      "0.06144967233382448\n",
      "0.008874933100824023\n",
      "0.041454905906007346\n",
      "0.3416609801709968\n",
      "0.00011638045220906159\n",
      "0.09001838333051311\n",
      "0.8772316839667647\n",
      "0.060755850855216564\n",
      "0.6668933487489712\n",
      "0.0033355142855807955\n",
      "0.0168001523027963\n",
      "0.0002586725329523724\n",
      "0.04507424752648597\n",
      "0.04276512258477841\n",
      "0.006734386330611377\n",
      "0.1143723881294428\n",
      "0.028722783659638797\n",
      "0.02089832284687067\n",
      "0.3153925158476216\n",
      "0.1106174948903033\n",
      "0.062037451916354035\n",
      "0.03890826267069944\n",
      "0.0008538235097177096\n",
      "0.11131700286536589\n",
      "0.006092933193478643\n",
      "0.2610491052370706\n",
      "0.00023901642677732639\n",
      "0.1280779561755631\n",
      "0.07014586133841864\n",
      "0.004594543612945761\n",
      "0.0041276639781771636\n",
      "0.26434869839560593\n",
      "0.00047943489436322757\n",
      "0.02943509640474201\n",
      "0.6358558327103185\n",
      "0.36531903293100765\n",
      "0.0010196061769854171\n",
      "0.04463494251318163\n",
      "0.17263269174920837\n",
      "0.10585041041614919\n",
      "0.008267700682844745\n",
      "0.007625745492413495\n",
      "0.43277609372422665\n",
      "0.13222548712817583\n",
      "0.0005160418600256494\n",
      "0.3333600803514708\n",
      "0.006691302336447221\n",
      "0.1098049447601952\n",
      "0.0063496998145839804\n",
      "0.1695076887095176\n",
      "0.002180795392789942\n",
      "0.18983960793857904\n",
      "0.03404310212371847\n",
      "0.02975038743120486\n",
      "0.02053279764849231\n",
      "0.05102579799387212\n",
      "0.00016226784190862917\n",
      "0.038449154853247736\n",
      "0.002824917119188458\n",
      "0.4279516051840119\n",
      "0.051753808428631524\n",
      "0.0026560300873373684\n",
      "0.8891114298381835\n",
      "0.013476465883620805\n",
      "0.35534723723936656\n",
      "0.18605479426468427\n",
      "0.1790037630801354\n",
      "0.10300977306903926\n",
      "0.0040132607463633846\n",
      "0.0694794741644043\n",
      "0.4263106650950982\n",
      "0.1125245374418713\n",
      "0.025575815203745366\n",
      "0.05970755703066688\n",
      "0.09133395536775596\n",
      "0.036435235242196426\n",
      "0.0018815758404571168\n",
      "0.19895198298552702\n",
      "5.0291207576659187e-05\n",
      "0.0024612431356737375\n",
      "0.11049047971688476\n",
      "0.02442328497484069\n",
      "0.7860904239717827\n",
      "0.2667991008052104\n",
      "0.05204874590916662\n",
      "0.00013843895478773177\n",
      "0.39605630998126606\n",
      "0.05378764673967778\n",
      "0.06606279251563829\n",
      "0.8928615963860356\n",
      "0.28601736672155376\n",
      "0.008562763183457662\n",
      "0.0068241199276093106\n",
      "0.00025353357031135474\n",
      "0.08850484101110084\n",
      "0.00027731330097032175\n",
      "0.0021733086000622205\n",
      "0.05523609456403051\n",
      "0.0014769575885372234\n",
      "0.13371226213999632\n",
      "0.037391904165364497\n",
      "0.3891391007898525\n",
      "0.006664553060618499\n",
      "0.005615529512103727\n",
      "0.00039784144973164663\n",
      "0.20630492057149716\n",
      "0.04049286248801196\n",
      "0.05963225077086028\n",
      "0.000285385283930784\n",
      "0.05265526691165992\n",
      "0.0518646770576945\n",
      "0.027147848849964802\n",
      "0.13007593335934176\n",
      "0.19927894480331554\n",
      "0.19203043766881264\n",
      "0.12265866784434014\n",
      "0.02723909727395798\n",
      "0.07002662591307536\n",
      "0.0022557125607836847\n",
      "0.10585021454242431\n",
      "We correctly recognized that the distribution was different in 499 out of 1000 experiments.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "import numpy as np\n",
    "\n",
    "correct_results = 0 # Start the counter at 0\n",
    "\n",
    "daily_visitors = np.genfromtxt(\"data/daily_visitors.csv\", delimiter=\",\")\n",
    "\n",
    "for i in range(1000): # 1000 experiments\n",
    "   #your ttest here:\n",
    "   t, pval = ttest_1samp(daily_visitors[i], 30) # perform t-test\n",
    "   if pval < 0.05: # check our p-value\n",
    "       correct_results += 1\n",
    "    #print the pvalue here:\n",
    "   print(pval)\n",
    "print(\"We correctly recognized that the distribution was different in \" + str(correct_results) + \" out of 1000 experiments.\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Sample T-Test\n",
    "Suppose that last week, the average amount of time spent per visitor to a website was 25 minutes. This week, the average amount of time spent per visitor to a website was 28 minutes. Did the average time spent per visitor change? Or is this part of natural fluctuations?\n",
    "\n",
    "One way of testing whether this difference is significant is by using a 2 Sample T-Test. A 2 Sample T-Test compares two sets of data, which are both approximately normally distributed.\n",
    "\n",
    "The null hypothesis, in this case, is that the two distributions have the same mean.\n",
    "\n",
    "We can use SciPy’s ttest_ind function to perform a 2 Sample T-Test. It takes the two distributions as inputs and returns the t-statistic (which we don’t use), and a p-value. If you can’t remember what a p-value is, refer to the earlier exercise on univariate t-tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dangers of Multiple T-Tests\n",
    "Suppose that we own a chain of stores that sell ants, called VeryAnts. There are three different locations: A, B, and C. We want to know if the average ant sales over the past year are significantly different between the three locations.\n",
    "\n",
    "At first, it seems that we could perform T-tests between each pair of stores.\n",
    "\n",
    "We know that the p-value is the probability that we incorrectly reject the null hypothesis on each t-test. The more t-tests we perform, the more likely that we are to get a false positive, a Type I error.\n",
    "\n",
    "For a p-value of 0.05, if the null hypothesis is true then the probability of obtaining a significant result is 1 – 0.05 = 0.95. When we run another t-test, the probability of still getting a correct result is 0.95 * 0.95, or 0.9025. That means our probability of making an error is now close to 10%! This error probability only gets bigger with the more t-tests we do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "We have created samples a, b, and c, representing the sales at VeryAnts at locations A, B, and C, respectively. We want to see if there’s a significant difference in sales between the three locations.\n",
    "\n",
    "Explore datasets a, b, and c by finding and printing the means and standard deviations of each one. Store the means in variables called a_mean, b_mean, and c_mean. Store the standard deviations in variables called a_std, b_std, and c_std.\n",
    "\n",
    "\n",
    "2.\n",
    "Perform a 2-Sample T-test between each pair of location data.\n",
    "\n",
    "Store the p-values in variables called a_b_pval, a_c_pval, and b_c_pval. Print them to the console.\n",
    "\n",
    "\n",
    "3.\n",
    "Store the probability of error in a variable called error_prob. Print it out to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7667629398748514e-05\n",
      "0.021012051698577176\n",
      "0.059885635239664836\n",
      "0.1426250000000001\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "\n",
    "a = np.genfromtxt(\"data/store_a.csv\",  delimiter=\",\")\n",
    "b = np.genfromtxt(\"data/store_b.csv\",  delimiter=\",\")\n",
    "c = np.genfromtxt(\"data/store_c.csv\",  delimiter=\",\")\n",
    "\n",
    "a_mean = np.mean(a)\n",
    "b_mean = np.mean(b)\n",
    "c_mean = np.mean(c)\n",
    "\n",
    "a_std = np.std(a)\n",
    "b_std = np.std(b)\n",
    "c_std = np.std(c)\n",
    "\n",
    "a_b_pval = ttest_ind(a, b).pvalue\n",
    "a_c_pval = ttest_ind(a, c).pvalue\n",
    "b_c_pval = ttest_ind(b, c).pvalue\n",
    "print(a_b_pval)\n",
    "print(a_c_pval)\n",
    "print(b_c_pval)\n",
    "\n",
    "error_prob = (1-(0.95**3))\n",
    "print(error_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA\n",
    "In the last exercise, we saw that the probability of making a Type I error got dangerously high as we performed more t-tests.\n",
    "\n",
    "When comparing more than two numerical datasets, the best way to preserve a Type I error probability of 0.05 is to use ANOVA. ANOVA (Analysis of Variance) tests the null hypothesis that all of the datasets have the same mean. If we reject the null hypothesis with ANOVA, we’re saying that at least one of the sets has a different mean; however, it does not tell us which datasets are different.\n",
    "\n",
    "We can use the SciPy function **f_oneway** to perform ANOVA on multiple datasets. It takes in each dataset as a different input and returns the t-statistic and the p-value. For example, if we were comparing scores on a videogame between math majors, writing majors, and psychology majors, we could run an ANOVA test with this line:\n",
    "\n",
    "    fstat, pval = f_oneway(scores_mathematicians, scores_writers, scores_psychologists)\n",
    "    \n",
    "The null hypothesis, in this case, is that all three populations have the same mean score on this videogame. If we reject this null hypothesis (if we get a p-value less than 0.05), we can say that we are reasonably confident that a pair of datasets is significantly different. After using only ANOVA, we can’t make any conclusions on which two populations have a significant difference.\n",
    "\n",
    "Let’s look at an example of ANOVA in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "Delete your three t-tests. We have a better way to do this now!\n",
    "\n",
    "Perform an ANOVA test on a, b, and c and store the p-value in a variable called pval.\n",
    "\n",
    "\n",
    "2.\n",
    "Print out your pval. Does this p-value lead you to reject the null hypothesis?\n",
    "\n",
    "\n",
    "3.\n",
    "Let’s say the sales at location B have suddenly soared (maybe there’s an ant convention happening nearby). Change the mean of the b distribution to be loaded from 'store_b_new.csv', instead of 'store_b.csv'.\n",
    "\n",
    "Re-run the ANOVA test and see what the p-value is now. Does this new value make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001534116600777967\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import f_oneway\n",
    "import numpy as np\n",
    "\n",
    "a = np.genfromtxt(\"data/store_a.csv\",  delimiter=\",\")\n",
    "b = np.genfromtxt(\"data/store_b.csv\",  delimiter=\",\")\n",
    "c = np.genfromtxt(\"data/store_c.csv\",  delimiter=\",\")\n",
    "\n",
    "stat, pval = f_oneway(a, b, c)\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumptions of Numerical Hypothesis Tests\n",
    "Before we use numerical hypothesis tests, we need to be sure that the following things are true:\n",
    "\n",
    "# 1. The samples should each be normally distributed…ish\n",
    "Data analysts in the real world often still perform hypothesis on sets that aren’t exactly normally distributed. What is more important is to recognize if there is some reason to believe that a normal distribution is especially unlikely. If your dataset is definitively not normal, the numerical hypothesis tests won’t work as intended.\n",
    "\n",
    "For example, imagine we have three datasets, each representing a day of traffic data in three different cities. Each dataset is independent, as traffic in one city should not impact traffic in another city. However, it is unlikely that each dataset is normally distributed. In fact, each dataset probably has two distinct peaks, one at the morning rush hour and one during the evening rush hour. The histogram of a day of traffic data might look something like this:\n",
    "\n",
    "<img src=images/histogram_data_traffic.svg width=400>\n",
    "\n",
    "In this scenario, using a numerical hypothesis test would be inappropriate.\n",
    "\n",
    "# 2. The population standard deviations of the groups should be equal\n",
    "For ANOVA and 2-Sample T-Tests, using datasets with standard deviations that are significantly different from each other will often obscure the differences in group means.\n",
    "\n",
    "To check for similarity between the standard deviations, it is normally sufficient to divide the two standard deviations and see if the ratio is “close enough” to 1. “Close enough” may differ in different contexts but generally staying within 10% should suffice.\n",
    "\n",
    "# 3. The samples must be independent\n",
    "When comparing two or more datasets, the values in one distribution should not affect the values in another distribution. In other words, knowing more about one distribution should not give you any information about any other distribution.\n",
    "\n",
    "Here are some examples where it would seem the samples are not independent:\n",
    "\n",
    "* the number of goals scored per soccer player before, during, and after undergoing a rigorous training regimen\n",
    "* a group of patients’ blood pressure levels before, during, and after the administration of a drug\n",
    "\n",
    "It is important to understand your datasets before you begin conducting hypothesis tests on it so that you know you are choosing the right test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "Use Matplotlib’s plt.hist function to display dist_1 before the call to plt.show. Does it look like this distribution is normal?\n",
    "\n",
    "\n",
    "2.\n",
    "Now, display histograms for dist_2, dist_3, and dist_4. Which of these distributions would probably not be a good choice to use in an ANOVA comparison? Create a variable called not_normal and set it equal to the distribution number that would be least suited to be used in an ANOVA test.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3.\n",
    "Calculate the ratio of standard deviations between dist_2 and dist_3 and store it in a variable called ratio. Print it to the console. Is this “close enough” to perform a numerical hypothesis test between the two datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5814221080397466\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dist_1 = np.genfromtxt(\"data/1.csv\",  delimiter=\",\")\n",
    "dist_2 = np.genfromtxt(\"data/2.csv\",  delimiter=\",\")\n",
    "dist_3 = np.genfromtxt(\"data/3.csv\",  delimiter=\",\")\n",
    "dist_4 = np.genfromtxt(\"data/4.csv\",  delimiter=\",\")\n",
    "\n",
    "#plot your histogram here\n",
    "#plt.hist(dist_1)\n",
    "#plt.hist(dist_2)\n",
    "#plt.hist(dist_3)\n",
    "plt.hist(dist_4)\n",
    "plt.show()\n",
    "\n",
    "not_normal = 4\n",
    "\n",
    "ratio = np.std(dist_2) / np.std(dist_3)\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tukey's Range Test\n",
    "Let’s say that we have performed ANOVA to compare three sets of data from the three VeryAnts stores. We received the result that there is some significant difference between datasets.\n",
    "\n",
    "Now, we have to find out which datasets are different.\n",
    "\n",
    "We can perform a Tukey’s Range Test to determine the difference between datasets.\n",
    "\n",
    "If we feed in three datasets, such as the sales at the VeryAnts store locations A, B, and C, Tukey’s Test can tell us which pairs of locations are distinguishable from each other.\n",
    "\n",
    "The function to perform Tukey’s Range Test is pairwise_tukeyhsd, which is found in statsmodel, not scipy. We have to provide the function with one list of all of the data and a list of labels that tell the function which elements of the list are from which set. We also provide the significance level we want, which is usually 0.05.\n",
    "\n",
    "For example, if we were looking to compare mean scores of movies that are dramas, comedies, or documentaries, we would make a call to pairwise_tukeyhsd like this:\n",
    "\n",
    "    movie_scores = np.concatenate([drama_scores, comedy_scores, documentary_scores])\n",
    "    labels = ['drama'] * len(drama_scores) + ['comedy'] * len(comedy_scores) + ['documentary'] * len(documentary_scores)\n",
    "\n",
    "    tukey_results = pairwise_tukeyhsd(movie_scores, labels, 0.05)\n",
    "    \n",
    "It will return a table of information, telling you whether or not to reject the null hypothesis for each pair of datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "We have concatenated the sales data in lists a, b, and c and put it into list v. We have also provided a labels list that keeps track of which elements of v come from a, b, or c.\n",
    "\n",
    "Use pairwise_tukeyhsd with these two lists and 0.05 (the desired significance level) as inputs. Store the results in a variable called tukey_results.\n",
    "\n",
    "\n",
    "2.\n",
    "Print tukey_results to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001534116600777967\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      "group1 group2 meandiff p-adj   lower   upper  reject\n",
      "----------------------------------------------------\n",
      "     a      b   7.2767  0.001  3.2266 11.3267   True\n",
      "     a      c   4.0115 0.0529 -0.0385  8.0616  False\n",
      "     b      c  -3.2651 0.1411 -7.3152  0.7849  False\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from scipy.stats import f_oneway\n",
    "import numpy as np\n",
    "\n",
    "a = np.genfromtxt(\"data/store_a.csv\",  delimiter=\",\")\n",
    "b = np.genfromtxt(\"data/store_b.csv\",  delimiter=\",\")\n",
    "c = np.genfromtxt(\"data/store_c.csv\",  delimiter=\",\")\n",
    "\n",
    "stat, pval = f_oneway(a, b, c)\n",
    "print(pval)\n",
    "\n",
    "# Using our data from ANOVA, we create v and l\n",
    "v = np.concatenate([a, b, c])\n",
    "labels = ['a'] * len(a) + ['b'] * len(b) + ['c'] * len(c)\n",
    "\n",
    "tukey_results = pairwise_tukeyhsd(v, labels, 0.05)\n",
    "\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binomial Test\n",
    "Let’s imagine that we are analyzing the percentage of customers who make a purchase after visiting a website. We have a set of 1000 customers from this month, 58 of whom made a purchase. Over the past year, the number of visitors per every 1000 who make a purchase hovers consistently at around 72. Thus, our marketing department has set our target number of purchases per 1000 visits to be 72. We would like to know if this month’s number, 58, is a significant difference from that target or a result of natural fluctuations.\n",
    "\n",
    "How do we begin comparing this, if there’s no mean or standard deviation that we can use? The data is divided into two discrete categories, “made a purchase” and “did not make a purchase”.\n",
    "\n",
    "So far, we have been working with numerical datasets. The tests we have looked at, the 1- and 2-Sample T-Tests, ANOVA, and Tukey’s Range test, will not work if we can’t find the means of our distributions and compare them.\n",
    "\n",
    "If we have a dataset where the entries are not numbers, but categories instead, we have to use different methods.\n",
    "\n",
    "To analyze a dataset like this, with two different possibilities for entries, we can use a Binomial Test. A Binomial Test compares a categorical dataset to some expectation.\n",
    "\n",
    "Examples include:\n",
    "\n",
    "* Comparing the actual percent of emails that were opened to the quarterly goals\n",
    "* Comparing the actual percentage of respondents who gave a certain survey response to the expected survey response\n",
    "* Comparing the actual number of heads from 1000 coin flips of a weighted coin to the expected number of heads\n",
    "\n",
    "The null hypothesis, in this case, would be that there is no difference between the observed behavior and the expected behavior. If we get a p-value of less than 0.05, we can reject that hypothesis and determine that there is a difference between the observation and expectation.\n",
    "\n",
    "SciPy has a function called binom_test, which performs a Binomial Test for you.\n",
    "\n",
    "binom_test requires three inputs, the number of observed successes, the number of total trials, and an expected probability of success. For example, with 1000 coin flips of a fair coin, we would expect a “success rate” (the rate of getting heads), to be 0.5, and the number of trials to be 1000. Let’s imagine we get 525 heads. Is the coin weighted? This function call would look like:\n",
    "\n",
    "    pval = binom_test(525, n=1000, p=0.5)\n",
    "    \n",
    "It returns a p-value, telling us how confident we can be that the sample of values was likely to occur with the specified probability. If we get a p-value less than 0.05, we can reject the null hypothesis and say that it is likely the coin is actually weighted, and that the probability of getting heads is statistically different than 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "Suppose the goal of VeryAnts’s marketing team this quarter was to have 6% of customers click a link that was emailed to them. They sent out a link to 10,000 customers and 510 clicked the link, which comes out to 5.1% instead of 6%. Did they do significantly worse than the target? Let’s use a binomial test to answer this question.\n",
    "\n",
    "Use SciPy’s binom_test function to calculate the p-value the experiment returns for this distribution, where we wanted the mean to be 6% of emails opened, or p=0.06, but only saw 5.1% of emails opened.\n",
    "\n",
    "Store the p-value in a variable called pval and print it out.\n",
    "\n",
    "\n",
    "\n",
    "### Hint\n",
    "Recall that the binom_test requires the following arguments:\n",
    "\n",
    "binom_test(x, n, p)\n",
    "x is the number of “successes” (0.051 * 10000 in this case)\n",
    "n is the number of samples (10000 in this case)\n",
    "p is the expected percentage of successes (0.06 in this case)\n",
    "\n",
    "\n",
    "2.\n",
    "For the next quarter, marketing has tried out a new email tactic, including puns in every line of every email. As a result, 590 people out of 10000 opened the link in the newest email.\n",
    "\n",
    "If we still wanted the mean to be 6% of emails opened, but now have 5.9% of emails opened, what is the new p-value. Save your results to the variable pval2\n",
    "\n",
    "Does this new p-value make sense?\n",
    "\n",
    "\n",
    "\n",
    "### Hint\n",
    "Recall that the binom_test requires the following arguments:\n",
    "\n",
    "binom_test(x, n, p)\n",
    "x is the number of “successes” (0.059 * 10000 in this case)\n",
    "n is the number of samples (10000 in this case)\n",
    "p is the expected percentage of successes (0.06 in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00011592032724546606\n",
      "0.6891529835730346\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom_test\n",
    "\n",
    "pval = binom_test(510, n=10000, p=0.06)\n",
    "print(pval)\n",
    "\n",
    "pval2 = binom_test(590, n=10000, p=0.06)\n",
    "print(pval2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi Square Test\n",
    "\n",
    "In the last exercise, we looked at data where customers visited a website and either made a purchase or did not make a purchase. What if we also wanted to track if visitors added any items to their shopping cart? With three discrete categories of data per dataset, we can no longer use a Binomial Test. If we have two or more categorical datasets that we want to compare, we should use a Chi Square test. It is useful in situations like:\n",
    "\n",
    "* An A/B test where half of users were shown a green submit button and the other half were shown a purple submit button. Was one group more likely to click the submit button?\n",
    "\n",
    "* Men and women were both given a survey asking “Which of the following three products is your favorite?” Did the men and women have significantly different preferences?\n",
    "In SciPy, you can use the function chi2_contingency to perform a Chi Square test.\n",
    "\n",
    "The input to chi2_contingency is a contingency table where:\n",
    "\n",
    "* The columns are each a different condition, such as men vs. women or Interface A vs. Interface B\n",
    "\n",
    "* The rows represent different outcomes, like “Survey Response A” vs. “Survey Response B” or “Clicked a Link” vs. “Didn’t Click”\n",
    "\n",
    "This table can have as many rows and columns as you need.\n",
    "\n",
    "In this case, the null hypothesis is that there’s no significant difference between the datasets. We reject that hypothesis, and state that there is a significant difference between two of the datasets if we get a p-value less than 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "The management at the VeryAnts ant store wants to know if their two most popular species of ants, the Leaf Cutter and the Harvester, vary in popularity between 1st, 2nd, and 3rd graders.\n",
    "\n",
    "We have created a table representing the different ants bought by the children in grades 1, 2, and 3 after the last big field trip to VeryAnts. Run the code to see what happens when we enter this table into SciPy’s chi-square test.\n",
    "\n",
    "Does the resulting p-value mean that we should reject or accept the null hypothesis?\n",
    "\n",
    "\n",
    "2.\n",
    "A class of 40 4th graders comes into VeryAnts in the next week and buys 20 sets of Leaf Cutter ants and 20 sets of Harvester ants.\n",
    "\n",
    "Add this data to the contingency table, rerun the chi-square test, and see if there is now a low enough value to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002812834559546625\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Contingency table\n",
    "#         harvester |  leaf cutter\n",
    "# ----+------------------+------------\n",
    "# 1st gr | 30       |  10\n",
    "# 2nd gr | 35       |  5\n",
    "# 3rd gr | 28       |  12\n",
    "# 4th gr | 20 .     |  20\n",
    "\n",
    "X = [[30, 10],\n",
    "     [35, 5],\n",
    "     [28, 12],\n",
    "     [20, 20]]\n",
    "chi2, pval, dof, expected = chi2_contingency(X)\n",
    "print(pval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
