{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "You’re a citizen scientist who has started collecting data about rising water in the river next to where you live. For months, you painstakingly measure the water levels and enter your findings into a notebook. But at the end of it, what exactly do you have? What can all this data tell us?\n",
    "\n",
    "In this lesson, we’ll explore how we can use NumPy to analyze data. We’ll learn different methods to calculate common statistical properties of a dataset, such as finding the mean and standard deviation. By the end, you’ll be able to do basic analysis of a dataset and understand how we can use statistics to come to conclusions about data.\n",
    "\n",
    "The statistical concepts that we’ll cover include:\n",
    "\n",
    "* Mean\n",
    "* Median\n",
    "* Percentiles\n",
    "* Interquartile Range\n",
    "* Outliers\n",
    "* Standard Deviation\n",
    "\n",
    "To start, we’ll be analyzing single-variable datasets. One way to think of a single-variable dataset is that it contains answers to a question. For instance, we might ask 100 people, “How tall are you?” Their heights in inches would form our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Statistics with NumPy\n",
    "After the river in your town flooded during a recent hurricane, you've become interested in collecting data about the its height. Every day for the past month, you walk to the river, measure the height of the water, and enter this information into a notebook.\n",
    "\n",
    "Let's look at how you can use NumPy functions to analyze your dataset.\n",
    "\n",
    "First, we'll import the NumPy module, so we can use its statistical calculation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "water_height = np.array([4.01, 4.03, 4.27, 4.29, 4.19,\n",
    "                         4.15, 4.16, 4.23, 4.29, 4.19,\n",
    "                         4.00, 4.22, 4.25, 4.19, 4.10,\n",
    "                         4.14, 4.03, 4.23, 4.08, 14.20,\n",
    "                         14.03, 11.20, 8.19, 6.18, 4.04,\n",
    "                         4.08, 4.11, 4.23, 3.99, 4.23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the function np.mean() to find the average water height:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.251"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(water_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait! We should sort our data to see if there could be any measurements to throw our data off, or represent a deviation from the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.99,  4.  ,  4.01,  4.03,  4.03,  4.04,  4.08,  4.08,  4.1 ,\n",
       "        4.11,  4.14,  4.15,  4.16,  4.19,  4.19,  4.19,  4.22,  4.23,\n",
       "        4.23,  4.23,  4.23,  4.25,  4.27,  4.29,  4.29,  6.18,  8.19,\n",
       "       11.2 , 14.03, 14.2 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(water_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like that thunderstorm might have impacted the average height! Let's measure the median to see if its more representative of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(water_height)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the median tells us where half of our data lies, let's look at a value closer to the end of the dataset. We can use percentiles to use a data points position and get its value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.265"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(water_height, 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've gotten a good idea about specific values. But what about the spread of our data? Let's calculate the standard deviation to understand how similar or how different each data point is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.784585367099861"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(water_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Just using a few simple functions we've been able to quickly calculate several important measurements and can begin analyzing our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy and Mean\n",
    "\n",
    "The first statistical concept we’ll explore is mean, also commonly referred to as an average. The mean is a useful measurement to get the center of a dataset. NumPy has a built-in function to calculate the average or mean of arrays: np.mean\n",
    "\n",
    "Let’s say we want to find the average number of pounds of produce a person purchases per week. We administered a survey and received 1,000 responses:\n",
    "\n",
    "    survey_responses = [5, 10.2, 4, .3 ... 6.6]\n",
    "We can then transform the dataset into a NumPy array and use the function np.mean to calculate the average:\n",
    "\n",
    "    >>> survey_array = np.array(survey_responses)\n",
    "    >>> np.mean(survey_array)\n",
    "    5.220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5\n",
      "10.428571428571429\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "store_one = np.array([2, 5, 8, 3, 4, 10, 15, 5])\n",
    "store_two = np.array([3, 17, 18,  9,  2, 14, 10])\n",
    "store_three = np.array([7, 5, 4, 3, 2, 7, 7])\n",
    "\n",
    "\n",
    "\n",
    "store_one_avg = np.mean(store_one)\n",
    "\n",
    "store_two_avg = np.mean(store_two)\n",
    "\n",
    "store_three_avg = np.mean(store_three)\n",
    "\n",
    "print(store_one_avg)\n",
    "print(store_two_avg)\n",
    "print(store_three_avg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the average sales per week for each store. The boss says that we should increase what we stock, but only if the store’s average sales are greater than 7 bottles per week.\n",
    "\n",
    "Save the store dataset variable name that fits this description to the variable best_seller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 17, 18,  9,  2, 14, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_seller = store_two\n",
    "best_seller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean and Logical Operations\n",
    "\n",
    "We can also use np.mean to calculate the percent of array elements that have a certain property.\n",
    "\n",
    "As we know, a logical operator will evaluate each item in an array to see if it matches the specified condition. If the item matches the given condition, the item will evaluate as True and equal 1. If it does not match, it will be False and equal 0.\n",
    "\n",
    "When np.mean calculates a logical statement, the resulting mean value will be equivalent to the total number of True items divided by the total array length.\n",
    "\n",
    "In our produce survey example, we can use this calculation to find out the percentage of people who bought more than 8 pounds of produce each week:\n",
    "\n",
    "    >>> np.mean(survey_array > 8)\n",
    "    0.2\n",
    "The logical statement survey_array > 8 evaluates which survey answers were greater than 8, and assigns them a value of 1. np.mean adds all of the 1s up and divides them by the length of survey_array. The resulting output tells us that 20% of responders purchased more than 8 pounds of produce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "You’re running an alumni reunion at your local college. You have a list of the names of each person in attendance and the year that they graduated.\n",
    "\n",
    "We’ve saved this list as a NumPy array to the variable class_year. Calculate the percent of attending alumni who graduated on and after 2005 and save your result to the variable millennials.\n",
    "\n",
    "\n",
    "2.\n",
    "Print the value of millennials to the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class_year = np.array([1967, 1949, 2004, 1997, 1953, 1950, 1958, 1974, 1987, 2006, 2013, 1978, 1951, 1998, 1996, 1952, 2005, 2007, 2003, 1955, 1963, 1978, 2001, 2012, 2014, 1948, 1970, 2011, 1962, 1966, 1978, 1988, 2006, 1971, 1994, 1978, 1977, 1960, 2008, 1965, 1990, 2011, 1962, 1995, 2004, 1991, 1952, 2013, 1983, 1955, 1957, 1947, 1994, 1978, 1957, 2016, 1969, 1996, 1958, 1994, 1958, 2008, 1988, 1977, 1991, 1997, 2009, 1976, 1999, 1975, 1949, 1985, 2001, 1952, 1953, 1949, 2015, 2006, 1996, 2015, 2009, 1949, 2004, 2010, 2011, 2001, 1998, 1967, 1994, 1966, 1994, 1986, 1963, 1954, 1963, 1987, 1992, 2008, 1979, 1987])\n",
    "\n",
    "\n",
    "millennials = np.mean(class_year>2005)\n",
    "\n",
    "print(millennials)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Mean of 2D Arrays\n",
    "\n",
    "If we have a two-dimensional array, np.mean can calculate the means of the larger array as well as the interior values.\n",
    "\n",
    "Let’s imagine a game of ring toss at a carnival. In this game, you have three different chances to get all three rings onto a stick. In our ring_toss array, each interior array (the arrays within the larger array) is one try, and each number is one ring toss. 1 represents a successful toss, 0 represents a fail.\n",
    "\n",
    "First, we can use np.mean to find the mean across all the arrays:\n",
    "\n",
    "    >>> ring_toss = np.array([[1, 0, 0], \n",
    "                              [0, 0, 1], \n",
    "                              [1, 0, 1]])\n",
    "    >>> np.mean(ring_toss)\n",
    "    0.44444444444444442\n",
    "    \n",
    "To find the means of each interior array, we specify axis 1 (the “rows”):\n",
    "\n",
    "    >>> np.mean(ring_toss, axis=1)\n",
    "    array([ 0.33333333,  0.33333333,  0.66666667])\n",
    "    \n",
    "To find the means of each index position (i.e, mean of all 1st tosses, mean of all 2nd tosses, …), we specify axis 0 (the “columns”):\n",
    "\n",
    "    >>> np.mean(ring_toss, axis=0)\n",
    "    array([ 0.66666667,  0.        ,  0.66666667])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "In script.py, we’ve provided data about a trial for a new allergy medication, AllerGeeThatSucks! Five participants were asked to rate how drowsy the medication made them once a day for three days on a scale of one (least drowsy) to ten (most drowsy).\n",
    "\n",
    "Use np.mean to find the average level of drowsiness across all the trials and save the result to the variable total_mean.\n",
    "\n",
    "\n",
    "2.\n",
    "Use np.mean to find the average level of drowsiness across each day of the experiment and save to the variable trial_mean.\n",
    "\n",
    "\n",
    "3.\n",
    "Use np.mean to find the average level of drowsiness across for each individual patient to see if some were more sensitive to the drug than others and save it to the variable patient_mean.\n",
    "\n",
    "\n",
    "4.\n",
    "Print the variables for total_mean, trial_mean, and patient_mean on three separate lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.266666666666667\n",
      "[4.  5.6 6.2]\n",
      "[4.33333333 3.         4.         8.66666667 6.33333333]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "allergy_trials = np.array([[6, 1, 3, 8, 2], \n",
    "                           [2, 6, 3, 9, 8], \n",
    "                           [5, 2, 6, 9, 9]])\n",
    "\n",
    "total_mean = np.mean(allergy_trials)\n",
    "\n",
    "trial_mean = np.mean(allergy_trials, axis=1)\n",
    "\n",
    "patient_mean = np.mean(allergy_trials, axis=0)\n",
    "\n",
    "print(total_mean)\n",
    "\n",
    "print(trial_mean)\n",
    "\n",
    "print(patient_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers\n",
    "\n",
    "As we can see, the mean is a helpful way to quickly understand different parts of our data. However, the mean is highly influenced by the specific values in our data set. What happens when one of those values is significantly different from the rest?\n",
    "\n",
    "Values that don’t fit within the majority of a dataset are known as outliers. It’s important to identify outliers because if they go unnoticed, they can skew our data and lead to error in our analysis (like determining the mean). They can also be useful in pointing out errors in our data collection.\n",
    "\n",
    "When we’re able to identify outliers, we can then determine if they were due to an error in sample collection or whether or not they represent a significant but real deviation from the mean.\n",
    "\n",
    "Suppose we want to determine the average height for 3rd graders. We measure several students at the local school, but accidentally measure one student in centimeters rather than in inches. If we’re not paying attention, our dataset could end up looking like this:\n",
    "\n",
    "    [50, 50, 51, 49, 48, 127]\n",
    "In this case, 127 would be an outlier.\n",
    "\n",
    "Some outliers aren’t the result of a mistake. For instance, suppose that one of our 3rd graders had skipped a grade and was actually a year younger than everyone else in the class:\n",
    "\n",
    "    [50, 50, 51, 49, 48, 45]\n",
    "She might be significantly shorter at 45”, but her height would still be an outlier.\n",
    "\n",
    "Suppose that another student was just unusually tall for his age:\n",
    "\n",
    "    [50, 50, 51, 49, 48, 58.5]\n",
    "His height of 58.5” would also be an outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "Explore the interactive visualization by clicking and dragging the circle* to change the value of the cluster of outliers.\n",
    "\n",
    "How does the value of the outliers affect the mean? What happens to the mean when the outliers are more similar to the rest of the set? What happens when the cluster is outside the expected range?\n",
    "\n",
    "If you don’t see the small blue circle on the axis, try opening this lesson in Chrome or refreshing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting and Outliers\n",
    "\n",
    "One way to quickly identify outliers is by sorting our data, Once our data is sorted, we can quickly glance at the beginning or end of an array to see if some values lie far beyond the expected range. We can use the NumPy function np.sort to sort our data.\n",
    "\n",
    "Let’s go back to our 3rd grade height example, and imagine an 8th grader walked into our experiement:\n",
    "\n",
    "    >>> heights = np.array([49.7, 46.9, 62, 47.2, 47, 48.3, 48.7])\n",
    "    \n",
    "If we use np.sort, we can immediately identify the taller student since their height (62”) is noticeably outside the range of the dataset:\n",
    "\n",
    "    >>> np.sort(heights)\n",
    "    array([ 46.9,  47. ,  47.2,  48.3,  48.7,  49.7,  62])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 85  85  85  85  85  86  86  86  86  86  86  86  87  87  87  87  87  87\n",
      "  87  88  88  88  88  88  88  88  88  89  89  90  90  90  90  90  90  90\n",
      "  90  91  91  91  92  92  92  92  92  93  93  93  93  93  94  94  94  94\n",
      "  94  94  94  95  95  96  96  96  96  96  96  97  97  97  97  97  98  98\n",
      "  98  98  98  98  99  99  99  99  99 100 101 101 187 191 195 196 198 199]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "temps = np.array([86, 88, 94, 85, 97, 90, 87, 85, 94, 93, 92, 95, 98, 85, 94, 91, 97, 88, 87, 86, 99, 89, 89, 99, 88, 96, 93, 96, 85, 88, 191, 95, 96, 87, 99, 93, 90, 86, 87, 100, 187, 98, 101, 101, 96, 94, 96, 87, 86, 92, 98,94, 98, 90, 99, 96, 99, 86, 97, 98, 86, 90, 86, 94, 91, 88, 196, 195,93, 97, 199, 87, 87, 90, 90, 98, 88, 92, 97, 88, 85, 94, 88, 93, 198, 90, 91, 90, 92, 92])\n",
    "\n",
    "sorted_temps  = np.sort(temps)\n",
    "\n",
    "print(sorted_temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy and Median\n",
    "\n",
    "Another key metric that we can use in data analysis is the median. The median is the middle value of a dataset that’s been ordered in terms of magnitude (from lowest to highest).\n",
    "\n",
    "Let’s look at the following array:\n",
    "\n",
    "    np.array( [1, 1, 2, 3, 4, 5, 5])\n",
    "    \n",
    "In this example, the median would be 3, because it is positioned half-way between the minimum value and the maximum value.\n",
    "\n",
    "If the length of our dataset was an even number, the median would be the value halfway between the two central values. So in the following example, the median would be 3.5:\n",
    "\n",
    "    np.array( [1, 1, 2, 3, 4, 5, 5, 6])\n",
    "    \n",
    "But what if we had a very large dataset? It would get very tedious to count all of the values. Luckily, NumPy also has a function to calculate the median, np.median:\n",
    "\n",
    "    >>> my_array = np.array([50, 38, 291, 59, 14])\n",
    "    >>> np.median(my_array)\n",
    "    50.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89691.5\n",
      "40500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "large_set = [173306.,  102204. ,  96767.  , 54264. ,  40898. ,  67887. , 118737. ,  74847.,\n",
    "  104813. , 122787.  ,122577.  ,113890.,  100576.,   90345.,   94656. ,  71403.,\n",
    "  153102.,  228233.  , 85628.  ,106708. ,  57289. ,  42279.,  157273. ,  71691.,\n",
    "   77030. , 111763.   ,30770. ,  69563.  ,126201., 114726. ,  78125.  , 42670.,\n",
    "  161304.  , 74165.  ,114605. ,  27270.   , 3283.  , 84450. , 106449. ,  89038.,\n",
    "   91897.  , 50975.  ,133062.  ,151264.   ,66383. ,  90675.  , 70498. ,  36092.,\n",
    "  160018.  , 58767. , 121995.  , 63990. , 226476. , 111729. , 127747. ,  57527.,\n",
    "  205382.  ,117022. , 147723. ,  71284.  ,119317. , 138942. ,  62945. , 121499.,\n",
    "   66940.  , 80725. ,  47357. ,  98913.   ,79435.  , 92556. , 151156. , 126723.,\n",
    "   65019.  ,187295.  , 47038. ,  40008.   ,79243.  , 45334. , 142448. ,  63090.,\n",
    "   92153.  ,251255.  , 50875. ,  46395.   ,76754.  , 43275.  , 43150. ,  57908.]\n",
    "\n",
    "\n",
    "\n",
    "small_set=[10100, 35500, 105000, 85000, 25500, 40500, 65000]\n",
    "small_set_median = 40500\n",
    "\n",
    "\n",
    "large_set_median = np.median(large_set)\n",
    "\n",
    "print(large_set_median)\n",
    "print(small_set_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean vs. Median\n",
    "In a dataset, the median value can provide an important comparison to the mean. Unlike a mean, the median is not affected by outliers. This becomes important in skewed datasets, datasets whose values are not distributed evenly. Let’s write a program that explores this idea further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentiles, Part I\n",
    "\n",
    "As we know, the median is the middle of a dataset: it is the number for which 50% of the samples are below, and 50% of the samples are above. But what if we wanted to find a point at which 40% of the samples are below, and 60% of the samples are above?\n",
    "\n",
    "This type of point is called a percentile. The Nth percentile is defined as the point N% of samples lie below it. So the point where 40% of samples are below is called the 40th percentile. Percentiles are useful measurements because they can tell us where a particular value is situated within the greater dataset.\n",
    "\n",
    "Let’s look at the following array:\n",
    "\n",
    "    d = [1, 2, 3, 4, 4, 4, 6, 6, 7, 8, 8]\n",
    "There are 11 numbers in the dataset. The 40th percentile will have 40% of the 10 remaining numbers below it (40% of 10 is 4) and 60% of the numbers above it (60% of 10 is 6). So in this example, the 40th percentile is 4.\n",
    "\n",
    "<img src='images/NumPy+40+percentile.svg' width>\n",
    "\n",
    "## percentile\n",
    "\n",
    "In NumPy, we can calculate percentiles using the function np.percentile, which takes two arguments: the array and the percentile to calculate.\n",
    "\n",
    "Here’s how we would use NumPy to calculate the 40th percentile of array d:\n",
    "\n",
    "    >>> d = np.array([1, 2, 3, 4, 4, 4, 6, 6, 7,  8, 8])\n",
    "    >>> np.percentile(d, 40)\n",
    "    4.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "1.\n",
    "The local public library wants to study how many hours a week their patrons use the computers. At the top of the script.py, we have included sample data from 11 users in a NumPy array.\n",
    "\n",
    "Use NumPy to find the 30th percentile of the sorted array and save it to a variable named thirtieth_percentile.\n",
    "\n",
    "\n",
    "2.\n",
    "Next, use NumPy to find the 70th percentile and save it to the variable seventieth_percentile.\n",
    "\n",
    "\n",
    "3.\n",
    "Print the 30th and 70th variables to the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "patrons = np.array([ 2, 6, 14, 4, 3, 9, 1, 11, 4, 2, 8])\n",
    "\n",
    "thirtieth_percentile = np.percentile(patrons, 30)\n",
    "\n",
    "seventieth_percentile  = np.percentile(patrons,70)\n",
    "\n",
    "print(thirtieth_percentile)\n",
    "\n",
    "print(seventieth_percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentiles, Part II\n",
    "\n",
    "Some percentiles have specific names:\n",
    "\n",
    "* The 25th percentile is called the first quartile\n",
    "\n",
    "* The 50th percentile is called the median\n",
    "\n",
    "* The 75th percentile is called the third quartile\n",
    "\n",
    "The minimum, first quartile, median, third quartile, and maximum of a dataset are called a five-number summary. This set of numbers is a great thing to compute when we get a new dataset.\n",
    "\n",
    "The difference between the first and third quartile is a value called the interquartile range. For example, say we have the following array:\n",
    "\n",
    "    d = [1, 2, 3, 4, 4, 4, 6, 6, 7, 8, 8]\n",
    "We can calculate the 25th and 75th percentiles using np.percentile:\n",
    "\n",
    "    np.percentile(d, 25)\n",
    "    >>> 3.5\n",
    "    np.percentile(d, 75)\n",
    "    >>> 6.5\n",
    "    \n",
    "Then to find the interquartile range, we subtract the value of the 25th percentile from the value of the 75th:\n",
    "\n",
    "    6.5 - 3.5 = 3\n",
    "50% of the dataset will lie within the interquartile range. The interquartile range gives us an idea of how spread out our data is. The smaller the interquartile range value, the less variance in our dataset. The greater the value, the larger the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "An online movie streaming company wants to know how many movies users watch in one week. At the top of the script.py, we have included sample data from 15 users in an array.\n",
    "\n",
    "Find the 25th and 75th percentiles, and save them to the corresponding variables: first_quarter and third_quarter.\n",
    "\n",
    "2.\n",
    "Create a variable named interquartile_range. Calculate the interquartile range and save it to this variable.\n",
    "\n",
    "\n",
    "3.\n",
    "Print the results of the 25th percentile, 75th percentile, and interquartile range to the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "3.5\n",
      "2.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "movies_watched = np.array([2, 3, 8, 0, 2, 4, 3, 1, 1, 0, 5, 1, 1, 7, 2])\n",
    "\n",
    "first_quarter  = np.percentile(movies_watched, 25)\n",
    "\n",
    "third_quarter  = np.percentile(movies_watched, 75)\n",
    "\n",
    "interquartile_range = third_quarter-first_quarter\n",
    "\n",
    "\n",
    "print(first_quarter)\n",
    "print(third_quarter)\n",
    "print(interquartile_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy and Standard Deviation, Part I\n",
    "While the mean and median can tell us about the center of our data, they do not reflect the range of the data. That’s where standard deviation comes in.\n",
    "\n",
    "Similar to the interquartile range, the standard deviation tells us the spread of the data. The larger the standard deviation, the more spread out our data is from the center. The smaller the standard deviation, the more the data is clustered around the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy and Standard Deviation, Part II\n",
    "As we saw in the last exercise, knowing the standard deviation of a dataset can help us understand how spread out our dataset is.\n",
    "\n",
    "We can find the standard deviation of a dataset using the Numpy function np.std:\n",
    "\n",
    "    >>> nums = np.array([65, 36, 52, 91, 63, 79])\n",
    "    >>> np.std(nums)\n",
    "    17.716909687891082"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "You’ve been asked to judge your town’s annual squash festival. The festival organizer gives you a list that includes all the weights for the two competitions that you’re judging: pumpkins and acorn squash.\n",
    "\n",
    "Given the two data sets at the top of script.py, find the average weight for each competition and save them to the variables pumpkin_avg and acorn_squash_avg.\n",
    "\n",
    "\n",
    "2.\n",
    "Now, the rest of the judges want you to give them an idea of how representative the mean values are in relation to the entirety of the submissions. Calculate the standard deviation for each of the datasets to find and save them to the variables pumpkin_std and acorn_squash_std. Print them to the console to see their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611.3183785884406\n",
      "87.22505374031019\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pumpkin = np.array([68, 1820, 1420, 2062, 704, 1156, 1857, 1755, 2092, 1384])\n",
    "\n",
    "acorn_squash = np.array([20, 43, 99, 200, 12, 250, 58, 120, 230, 215])\n",
    "\n",
    "pumpkin_avg = np.mean(pumpkin)\n",
    "\n",
    "acorn_squash_avg = np.mean(acorn_squash)\n",
    "\n",
    "pumpkin_std = np.std(pumpkin)\n",
    "\n",
    "acorn_squash_std = np.std(acorn_squash)\n",
    "\n",
    "print(pumpkin_std)\n",
    "\n",
    "print(acorn_squash_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "Let’s review! In this lesson, you learned how to use NumPy to analyze single-variable datasets. Here’s what we covered:\n",
    "\n",
    "* Using the np.sort method to locate outliers.\n",
    "* Calculating central positions of a dataset using np.mean and np.median.\n",
    "* Understanding the spread of our data using percentiles and the interquartile range.\n",
    "* Finding the standard deviation of a dataset using np.std.\n",
    "\n",
    "In our next lesson, we’ll continue our exploration of NumPy and see how we can use it to analyze different statistical distributions. Follow the checkpoints below to practice what you just learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.895\n",
      "2.81\n",
      "1.6775\n",
      "4.025\n",
      "2.3475\n",
      "1.5267312577311483\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rainfall = np.array([5.21, 3.76, 3.27, 2.35, 1.89, 1.55, 0.65, 1.06, 1.72, 3.35, 4.82, 5.11])\n",
    "\n",
    "rain_mean = np.mean(rainfall)\n",
    "rain_median = np.median(rainfall)\n",
    "\n",
    "first_quarter = np.percentile(rainfall, 25)\n",
    "\n",
    "third_quarter = np.percentile(rainfall, 75)\n",
    "\n",
    "interquartile_range = third_quarter - first_quarter\n",
    "\n",
    "rain_std = np.std(rainfall)\n",
    "\n",
    "print(rain_mean)\n",
    "print(rain_median)\n",
    "print(first_quarter)\n",
    "print(third_quarter)\n",
    "print(interquartile_range)\n",
    "print(rain_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
